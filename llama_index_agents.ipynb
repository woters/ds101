{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woters/ds101/blob/master/llama_index_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x7wjl4UX2gP"
      },
      "source": [
        "### Install TruLens and Llama-Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn9BbqG3fKy1",
        "outputId": "6d3f4750-c5cd-441f-911c-710e0ace0a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trulens\n",
            "  Downloading trulens-1.2.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting trulens-apps-llamaindex\n",
            "  Downloading trulens_apps_llamaindex-1.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting trulens-providers-openai\n",
            "  Downloading trulens_providers_openai-1.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama_index\n",
            "  Downloading llama_index-0.11.23-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Collecting llama-index-tools-yelp\n",
            "  Downloading llama_index_tools_yelp-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting trulens-core<2.0.0,>=1.0.0 (from trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading trulens_core-1.2.6-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting trulens-dashboard<2.0.0,>=1.0.0 (from trulens)\n",
            "  Downloading trulens_dashboard-1.2.6-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting trulens-feedback<2.0.0,>=1.0.0 (from trulens)\n",
            "  Downloading trulens_feedback-1.2.6-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting trulens_eval<2.0.0,>=1.0.0 (from trulens)\n",
            "  Downloading trulens_eval-1.2.6-py3-none-any.whl.metadata (1000 bytes)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from trulens-apps-llamaindex) (2.9.2)\n",
            "Collecting trulens-apps-langchain<2.0.0,>=1.0.0 (from trulens-apps-llamaindex)\n",
            "  Downloading trulens_apps_langchain-1.2.6-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting langchain-community>=0.0.20 (from trulens-providers-openai)\n",
            "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama_index)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.23 (from llama_index)\n",
            "  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.4.0,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting nltk>3.8.1 (from llama_index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting yelpapi<3.0.0,>=2.5.1 (from llama-index-tools-yelp)\n",
            "  Downloading yelpapi-2.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (3.10.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.3.15)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.1.139)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community>=0.0.20->trulens-providers-openai) (9.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (1.2.14)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.23->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.23->llama_index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (10.4.0)\n",
            "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.23->llama_index)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.23->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama_index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index)\n",
            "  Downloading llama_cloud-0.1.4-py3-none-any.whl.metadata (814 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama_index) (4.12.3)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.4.0,>=0.3.0->llama_index)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.4.0,>=0.3.0->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama_index)\n",
            "  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens-apps-llamaindex) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->trulens-apps-llamaindex) (2.23.4)\n",
            "INFO: pip is looking at multiple versions of trulens-apps-langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting trulens-apps-langchain<2.0.0,>=1.0.0 (from trulens-apps-llamaindex)\n",
            "  Downloading trulens_apps_langchain-1.2.5-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.2.4-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.2.2-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.2.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.2.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading trulens_apps_langchain-1.1.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting alembic<2.0.0,>=1.8.1 (from trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting dill>=0.3.8 (from trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting munch<3.0,>=2.5 (from trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting python-dotenv<2.0,>=0.21 (from trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: rich<14.0,>=13.6 in /usr/local/lib/python3.10/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (13.9.4)\n",
            "\u001b[33mWARNING: trulens-core 1.2.6 does not provide the extra 'openai'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: trulens-core 1.2.6 does not provide the extra 'otel'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: trulens-core 1.2.6 does not provide the extra 'tqdm'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting ipywidgets<9.0.0,>=8.1.2 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jupyter<2,>=1 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.22.0 in /usr/local/lib/python3.10/dist-packages (from trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.24.1)\n",
            "Requirement already satisfied: psutil<6.0,>=5.9 in /usr/local/lib/python3.10/dist-packages (from trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.9.5)\n",
            "Collecting streamlit<2.0,>=1.37 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting streamlit-aggrid<2.0.0,>=1.0.5 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_aggrid-1.0.5-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting streamlit-extras>=0.4 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_extras-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting streamlit-pills>=0.3 (from trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_pills-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: traitlets<6.0.0,>=5.0.5 in /usr/local/lib/python3.10/dist-packages (from trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.7.1)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trulens-feedback<2.0.0,>=1.0.0->trulens) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from trulens-feedback<2.0.0,>=1.0.0->trulens) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (4.0.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.8.1->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.4.0,>=0.3.0->llama_index) (2.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.0.20->trulens-providers-openai)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting comm>=0.1.3 (from ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (7.34.0)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.0.13)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (7.16.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.5.6)\n",
            "Collecting jupyterlab (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyterlab-4.3.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community>=0.0.20->trulens-providers-openai) (0.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community>=0.0.20->trulens-providers-openai) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community>=0.0.20->trulens-providers-openai) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community>=0.0.20->trulens-providers-openai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community>=0.0.20->trulens-providers-openai) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch<3.0,>=2.5->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community>=0.0.20->trulens-providers-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community>=0.0.20->trulens-providers-openai) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=13.6->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=13.6->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.3.0->trulens-feedback<2.0.0,>=1.0.0->trulens) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community>=0.0.20->trulens-providers-openai) (3.1.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.5.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (17.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (6.3.3)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-decouple<4.0,>=3.6 (from streamlit-aggrid<2.0.0,>=1.0.5->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading python_decouple-3.8-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.4)\n",
            "Collecting htbuilder>=0.6.2 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading htbuilder-0.6.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting markdownlit>=0.0.5 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading markdownlit-0.0.7-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.21.0)\n",
            "Collecting st-annotated-text>=3.0.0 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading st_annotated_text-4.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting st-theme>=1.0.1 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading st_theme-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting streamlit-card>=0.0.4 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_card-1.0.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting streamlit-embedcode>=0.1.2 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl.metadata (414 bytes)\n",
            "Collecting streamlit-faker>=0.0.2 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_faker-0.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-keyup>=0.1.9 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_keyup-0.2.4-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl.metadata (395 bytes)\n",
            "Collecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting validators>=0.20.0 (from streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.23->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.0.11)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from htbuilder>=0.6.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (10.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community>=0.0.20->trulens-providers-openai) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=13.6->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.3.0)\n",
            "Collecting favicon (from markdownlit>=0.0.5->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading favicon-0.7.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading pymdown_extensions-10.12-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting faker (from streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading Faker-30.8.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.8.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (0.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (6.1.12)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting ipykernel (from jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.2.4)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (2.0.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.8.1->trulens-core<2.0.0,>=1.0.0->trulens-core[openai,otel,tqdm]<2.0.0,>=1.0.0->trulens) (3.0.2)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.4.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.18.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.5.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0,>=1.37->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.20.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.3.6)\n",
            "Collecting jupyter-client (from jupyter-console->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading json5-0.9.28-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (2.20.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets<9.0.0,>=8.1.2->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4->trulens-dashboard<2.0.0,>=1.0.0->trulens) (3.2.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens) (24.8.0)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter<2,>=1->trulens-dashboard<2.0.0,>=1.0.0->trulens)\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading trulens-1.2.6-py3-none-any.whl (3.6 kB)\n",
            "Downloading trulens_apps_llamaindex-1.2.6-py3-none-any.whl (9.8 kB)\n",
            "Downloading trulens_providers_openai-1.2.6-py3-none-any.whl (9.1 kB)\n",
            "Downloading llama_index-0.11.23-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_tools_yelp-0.2.0-py3-none-any.whl (3.4 kB)\n",
            "Downloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.3.0-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trulens_apps_langchain-1.1.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading trulens_core-1.2.6-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trulens_dashboard-1.2.6-py3-none-any.whl (600 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.3/600.3 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trulens_eval-1.2.6-py3-none-any.whl (37 kB)\n",
            "Downloading trulens_feedback-1.2.6-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yelpapi-2.5.1-py3-none-any.whl (7.4 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.8/176.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.13-py3-none-any.whl (13 kB)\n",
            "Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_aggrid-1.0.5-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_extras-0.5.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_pills-0.3.0-py3-none-any.whl (706 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.3/706.3 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading htbuilder-0.6.2-py3-none-any.whl (12 kB)\n",
            "Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
            "Downloading st_annotated_text-4.0.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading st_theme-1.2.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading streamlit_card-1.0.2-py3-none-any.whl (680 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
            "Downloading streamlit_faker-0.0.3-py3-none-any.whl (14 kB)\n",
            "Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl (7.0 kB)\n",
            "Downloading streamlit_keyup-0.2.4-py3-none-any.whl (7.4 kB)\n",
            "Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.0-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Faker-30.8.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading pymdown_extensions-10.12-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.4/263.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.28-py3-none-any.whl (30 kB)\n",
            "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Installing collected packages: striprtf, python-decouple, filetype, dirtyjson, widgetsnbextension, watchdog, validators, uri-template, types-python-dateutil, tenacity, SQLAlchemy, rfc3986-validator, rfc3339-validator, python-json-logger, python-dotenv, pypdf, pymdown-extensions, overrides, nltk, mypy-extensions, munch, marshmallow, Mako, json5, jedi, httpx-sse, htbuilder, fqdn, dill, comm, async-lru, yelpapi, typing-inspect, tiktoken, st-annotated-text, pydeck, jupyter-server-terminals, jupyter-client, favicon, faker, arrow, alembic, trulens-core, pydantic-settings, llama-cloud, isoduration, ipywidgets, ipykernel, dataclasses-json, trulens-feedback, llama-index-legacy, llama-index-core, streamlit, llama-parse, llama-index-tools-yelp, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, jupyter-events, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-pills, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-aggrid, st-theme, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, trulens-apps-langchain, llama-index-program-openai, langchain-community, jupyter-server, trulens-providers-openai, llama-index-question-gen-openai, jupyterlab-server, jupyter-lsp, llama_index, jupyterlab, trulens-apps-llamaindex, jupyter, streamlit-faker, markdownlit, streamlit-extras, trulens_eval, trulens-dashboard, trulens\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.6 SQLAlchemy-2.0.35 alembic-1.14.0 arrow-1.3.0 async-lru-2.0.4 comm-0.2.2 dataclasses-json-0.6.7 dill-0.3.9 dirtyjson-1.0.8 faker-30.8.2 favicon-0.7.0 filetype-1.2.0 fqdn-1.5.1 htbuilder-0.6.2 httpx-sse-0.4.0 ipykernel-6.29.5 ipywidgets-8.1.5 isoduration-20.11.0 jedi-0.19.2 json5-0.9.28 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.3.0 jupyterlab-server-2.27.3 langchain-community-0.3.5 llama-cloud-0.1.4 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.23 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.3.0 llama-index-readers-llama-parse-0.3.0 llama-index-tools-yelp-0.2.0 llama-parse-0.5.13 llama_index-0.11.23 markdownlit-0.0.7 marshmallow-3.23.1 munch-2.5.0 mypy-extensions-1.0.0 nltk-3.9.1 overrides-7.7.0 pydantic-settings-2.6.1 pydeck-0.9.1 pymdown-extensions-10.12 pypdf-5.1.0 python-decouple-3.8 python-dotenv-1.0.1 python-json-logger-2.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 st-annotated-text-4.0.1 st-theme-1.2.3 streamlit-1.40.1 streamlit-aggrid-1.0.5 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.2 streamlit-embedcode-0.1.2 streamlit-extras-0.5.0 streamlit-faker-0.0.3 streamlit-image-coordinates-0.1.9 streamlit-keyup-0.2.4 streamlit-pills-0.3.0 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.8.0 trulens-1.2.6 trulens-apps-langchain-1.1.0 trulens-apps-llamaindex-1.2.6 trulens-core-1.2.6 trulens-dashboard-1.2.6 trulens-feedback-1.2.6 trulens-providers-openai-1.2.6 trulens_eval-1.2.6 types-python-dateutil-2.9.0.20241003 typing-inspect-0.9.0 uri-template-1.3.0 validators-0.34.0 watchdog-6.0.0 widgetsnbextension-4.0.13 yelpapi-2.5.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install trulens_eval llama_index llama-index-tools-yelp==0.1.2 trulens-providers-openai>=1.0.0 #langchain\n",
        "#!pip install langchain langchain-core llama-index-core llama-index-tools-yelp #trulens-apps-llamaindex>=1.0.0\n",
        "\n",
        "!pip install trulens trulens-apps-llamaindex trulens-providers-openai llama_index openai llama-index-tools-yelp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai"
      ],
      "metadata": {
        "id": "gOl5bG-o-jML"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oY9A_hltX2gS"
      },
      "outputs": [],
      "source": [
        "import llama_index\n",
        "from llama_index.agent.openai import OpenAIAgent\n",
        "import openai\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wLgAZvErX2gS"
      },
      "outputs": [],
      "source": [
        "# Set your API keys. If you already have them in your var env., you can skip these steps.\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "os.environ[\"YELP_API_KEY\"] = \"6RedxTkcNZswb6RaKC0pSWhyJtn_8ywEupkQu3cFl3bFEgTJO9iLZ28qR6Oo69HhcO8yHFRjb7M-I7w5aUJpmINK2Zl4wGm2QKlZViST0qfxhZPZjszUXMe7rzXbZXYx\"\n",
        "os.environ[\"YELP_CLIENT_ID\"] = \"ZzMGXB8TbxtRTleH_aIFZg\"\n",
        "\n",
        "# If you already have keys in var env., use these to check instead:\n",
        "# from trulens_eval.keys import check_keys\n",
        "# check_keys(\"OPENAI_API_KEY\", \"YELP_API_KEY\", \"YELP_CLIENT_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sZ9RF_6X2gT"
      },
      "source": [
        "### Set up our Llama-Index App\n",
        "\n",
        "For this app, we will use a tool from Llama-Index to connect to Yelp and allow the Agent to search for business and fetch reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5aUsWQlwX2gU"
      },
      "outputs": [],
      "source": [
        "# Import and initialize our tool spec\n",
        "from llama_index.tools.yelp.base import YelpToolSpec\n",
        "from llama_index.core.tools.tool_spec.load_and_search import (\n",
        "    LoadAndSearchToolSpec,\n",
        ")\n",
        "\n",
        "# Add Yelp API key and client ID\n",
        "tool_spec = YelpToolSpec(\n",
        "    api_key=os.environ.get(\"YELP_API_KEY\"),\n",
        "    client_id=os.environ.get(\"YELP_CLIENT_ID\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pM8rXmCEX2gU"
      },
      "outputs": [],
      "source": [
        "gordon_ramsay_prompt = \"You answer questions about restaurants in the style of Gordon Ramsay, often insulting the asker.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LcgFJ7K5X2gV"
      },
      "outputs": [],
      "source": [
        "# Create the Agent with our tools\n",
        "tools = tool_spec.to_tool_list()\n",
        "agent = OpenAIAgent.from_tools([\n",
        "        *LoadAndSearchToolSpec.from_defaults(tools[0]).to_tool_list(),\n",
        "        *LoadAndSearchToolSpec.from_defaults(tools[1]).to_tool_list()\n",
        "    ],\n",
        "    verbose=True,\n",
        "    system_prompt=gordon_ramsay_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNd7EWzzX2gW"
      },
      "source": [
        "### Create a standalone GPT3.5 for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iyuYQ_j_g4Ms"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "chat_completion = client.chat.completions.create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_1qTWpGxX2gW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7c59bc-f49c-4128-bcc2-d9d5675af6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b082f27626b3>:1: DeprecationWarning: The `trulens_eval` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
            "  from trulens_eval.tru_custom_app import TruCustomApp, instrument\n",
            "<ipython-input-9-b082f27626b3>:1: DeprecationWarning: The `trulens_eval.tru_custom_app` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
            "  from trulens_eval.tru_custom_app import TruCustomApp, instrument\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval.tru_custom_app import TruCustomApp, instrument\n",
        "from trulens_eval import TruCustomApp\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "\n",
        "class LLMStandaloneApp():\n",
        "    @instrument\n",
        "    def __call__(self, prompt):\n",
        "        return chat_completion(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                    {\"role\": \"system\", \"content\": gordon_ramsay_prompt},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "        ).choices[0].message.content\n",
        "\n",
        "llm_standalone = LLMStandaloneApp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bxeKoPX2gX"
      },
      "source": [
        "## Evaluation and Tracking with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lByWI1c8X2gX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1becc71-55b8-4e7b-fb5c-3734dd1a487e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d55901198669>:3: DeprecationWarning: The `trulens_eval.feedback` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
            "  from trulens_eval.feedback import GroundTruthAgreement#, GroundeGroundTruthAgreementdness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦑 Initialized with db url sqlite:///default.sqlite .\n",
            "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_id in records table: 0it [00:00, ?it/s]\n",
            "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# imports required for tracking and evaluation\n",
        "from trulens_eval import Feedback, OpenAI, Tru, TruLlama, Select, OpenAI as fOpenAI\n",
        "from trulens_eval.feedback import GroundTruthAgreement#, GroundeGroundTruthAgreementdness\n",
        "\n",
        "tru = Tru()\n",
        "# tru.reset_database() # if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK_dfR06X2gX"
      },
      "source": [
        "## Evaluation setup\n",
        "\n",
        "To set up our evaluation, we'll first create two new custom feedback functions: query_translation_score and ratings_usage. These are straight-forward prompts of the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ccpVccEgX2gX"
      },
      "outputs": [],
      "source": [
        "class Custom_OpenAI(OpenAI):\n",
        "    def query_translation_score(self, question1: str, question2: str) -> float:\n",
        "        prompt = f\"Your job is to rate how similar two quesitons are on a scale of 1 to 10. Respond with the number only. QUESTION 1: {question1}; QUESTION 2: {question2}\"\n",
        "        return self.generate_score_and_reason(system_prompt = prompt)\n",
        "\n",
        "    def ratings_usage(self, last_context: str) -> float:\n",
        "        prompt = f\"Your job is to respond with a '1' if the following statement mentions ratings or reviews, and a '0' if not. STATEMENT: {last_context}\"\n",
        "        return self.generate_score_and_reason(system_prompt = prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom = Custom_OpenAI()"
      ],
      "metadata": {
        "id": "PASPtVyg8JwV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LR7RpFwX2gY"
      },
      "source": [
        "Now that we have all of our feedback functions available, we can instantiate them. For many of our evals, we want to check on intermediate parts of our app such as the query passed to the yelp app, or the summarization of the Yelp content. We'll do so here using Select."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4qKkPU4oX2gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfc77f5-00ae-4f68-c14a-8c27a66c2840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Query Translation, input question1 will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Query Translation, input question2 will be set to __record__.app.query[0].args.str_or_query_bundle .\n",
            "✅ In Ratings Usage, input last_context will be set to __record__.app.query[0].rets.response .\n",
            "✅ In Context Relevance, input args will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Context Relevance, input kwargs will be set to __record__.app.query[0].rets.response .\n",
            "✅ In Groundedness, input source will be set to __record__.app.query[0].rets.response .\n",
            "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ],
      "source": [
        "# unstable: perhaps reduce temperature?\n",
        "\n",
        "custom = Custom_OpenAI()\n",
        "# Input to tool based on trimmed user input.\n",
        "f_query_translation = Feedback(\n",
        "    custom.query_translation_score,\n",
        "    name=\"Query Translation\") \\\n",
        ".on_input() \\\n",
        ".on(Select.Record.app.query[0].args.str_or_query_bundle)\n",
        "\n",
        "f_ratings_usage = Feedback(\n",
        "    custom.ratings_usage,\n",
        "    name=\"Ratings Usage\") \\\n",
        ".on(Select.Record.app.query[0].rets.response)\n",
        "\n",
        "# Result of this prompt: Given the context information and not prior knowledge, answer the query.\n",
        "# Query: address of Gumbo Social\n",
        "# Answer: \"\n",
        "fopenai = fOpenAI()\n",
        "# Question/statement (context) relevance between question and last context chunk (i.e. summary)\n",
        "f_context_relevance = Feedback(\n",
        "    fopenai.qs_relevance,\n",
        "    name=\"Context Relevance\") \\\n",
        ".on_input() \\\n",
        ".on(Select.Record.app.query[0].rets.response)\n",
        "\n",
        "# Groundedness\n",
        "#grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "\n",
        "f_groundedness = Feedback(\n",
        "    fopenai.groundedness_measure_with_cot_reasons, name = \"Groundedness\") \\\n",
        ".on(Select.Record.app.query[0].rets.response) \\\n",
        ".on_output()#.aggregate(grounded.grounded_statements_aggregator)\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = Feedback(\n",
        "    fopenai.relevance,\n",
        "    name=\"Answer Relevance\"\n",
        ").on_input_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3wNcOTzX2gY"
      },
      "source": [
        "### Ground Truth Eval\n",
        "\n",
        "It's also useful in many cases to do ground truth eval with small golden sets. We'll do so here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NGkx8fi0X2gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9f1511-aa47-4f2e-8f53-1797009fce72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Ground Truth Eval, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Ground Truth Eval, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ],
      "source": [
        "golden_set = [\n",
        "    {\"query\": \"Hello there mister AI. What's the vibe like at oprhan andy's in SF?\", \"response\": \"welcoming and friendly\"},\n",
        "    {\"query\": \"Is park tavern in San Fran open yet?\", \"response\": \"Yes\"},\n",
        "    {\"query\": \"I'm in san francisco for the morning, does Juniper serve pastries?\", \"response\": \"Yes\"},\n",
        "    {\"query\": \"What's the address of Gumbo Social in San Francisco?\", \"response\": \"5176 3rd St, San Francisco, CA 94124\"},\n",
        "    {\"query\": \"What are the reviews like of Gola in SF?\", \"response\": \"Excellent, 4.6/5\"},\n",
        "    {\"query\": \"Where's the best pizza in New York City\", \"response\": \"Joe's Pizza\"},\n",
        "    {\"query\": \"What's the best diner in Toronto?\", \"response\": \"The George Street Diner\"}\n",
        "]\n",
        "\n",
        "f_groundtruth = Feedback(\n",
        "    GroundTruthAgreement(golden_set).agreement_measure,\n",
        "    name=\"Ground Truth Eval\") \\\n",
        ".on_input_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCcgA40zX2gY"
      },
      "source": [
        "### Run the dashboard\n",
        "\n",
        "By running the dashboard before we start to make app calls, we can see them come in 1 by 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EwBDGkDaX2gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a92610-8632-4a04-e34f-33d32ea36398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-32f881b2968e>:1: DeprecationWarning: Method `run_dashboard` has been renamed or moved to `trulens.dashboard.run.run_dashboard`.\n",
            "\n",
            "  tru.run_dashboard(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "npm WARN exec The following package was not found and will be installed: localtunnel@2.0.2\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://hot-cloths-know.loca.lt\n",
            "\n",
            "  Submit this IP Address: 35.221.210.67\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tru.run_dashboard(\n",
        "#     _dev=trulens_path, force=True  # if running from github\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import TruLlama"
      ],
      "metadata": {
        "id": "Rc_g-34OYeyI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install trulens-apps-llamaindex>=1.0.0"
      ],
      "metadata": {
        "id": "38L9x5Kbc0_7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8V7ch-kX2gZ"
      },
      "source": [
        "### Instrument Yelp App\n",
        "\n",
        "We can instrument our yelp app with TruLlama and utilize the full suite of evals we set up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DGHRn6g7X2gZ"
      },
      "outputs": [],
      "source": [
        "tru_agent = TruLlama(agent,\n",
        "    app_id='YelpAgent',\n",
        "    tags = \"agent prototype\",\n",
        "    feedbacks = [\n",
        "        f_qa_relevance,\n",
        "        f_groundtruth,\n",
        "        f_context_relevance,\n",
        "        f_groundedness,\n",
        "        f_query_translation,\n",
        "        f_ratings_usage\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wmKbsnVlX2gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab36b858-00ec-43e1-b897-f33d31846b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Components:\n",
            "\tTruLlama (Custom) at 0x7d510a738950 with path __app__\n",
            "\tOpenAIAgent (Custom) at 0x7d510f35a410 with path __app__.app\n",
            "\tChatMemoryBuffer (Custom) at 0x7d510e11d4e0 with path __app__.app.memory\n",
            "\tSimpleChatStore (Custom) at 0x7d510e976fc0 with path __app__.app.memory.chat_store\n",
            "\n",
            "Methods:\n",
            "Object at 0x7d510e11d4e0:\n",
            "\t<function BaseChatStoreMemory.put at 0x7d51102d27a0> with path __app__.app.memory\n",
            "\t<function BaseMemory.put at 0x7d51102d1ea0> with path __app__.app.memory\n",
            "Object at 0x7d510f35a410:\n",
            "\t<function AgentRunner.chat at 0x7d510eaee7a0> with path __app__.app\n",
            "\t<function AgentRunner.stream_chat at 0x7d510eaee440> with path __app__.app\n",
            "\t<function AgentRunner.achat at 0x7d510eaeed40> with path __app__.app\n",
            "\t<function AgentRunner.astream_chat at 0x7d510eaef0a0> with path __app__.app\n",
            "\t<function BaseQueryEngine.query at 0x7d51108a23b0> with path __app__.app\n",
            "\t<function BaseQueryEngine.aquery at 0x7d51108a32e0> with path __app__.app\n",
            "\t<function BaseQueryEngine.synthesize at 0x7d51108a3370> with path __app__.app\n",
            "\t<function BaseQueryEngine.asynthesize at 0x7d51108a3130> with path __app__.app\n",
            "\t<function BaseQueryEngine.retrieve at 0x7d51108a3400> with path __app__.app\n",
            "\t<function BaseChatEngine.chat at 0x7d51101f2f80> with path __app__.app\n",
            "\t<function BaseAgent.stream_chat at 0x7d510f15ed40> with path __app__.app\n",
            "\t<function BaseChatEngine.achat at 0x7d51101f2b90> with path __app__.app\n",
            "\t<function BaseAgent.astream_chat at 0x7d510f15ef80> with path __app__.app\n",
            "\t<function BaseChatEngine.stream_chat at 0x7d51101f3eb0> with path __app__.app\n",
            "\t<function BaseChatEngine.astream_chat at 0x7d5110244430> with path __app__.app\n"
          ]
        }
      ],
      "source": [
        "tru_agent.print_instrumented()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKP5E4gQX2gZ"
      },
      "source": [
        "### Instrument Standalone LLM app.\n",
        "\n",
        "Since we don't have insight into the OpenAI innerworkings, we cannot run many of the evals on intermediate steps.\n",
        "\n",
        "We can still do QA relevance on input and output, and check for similarity of the answers compared to the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DSjKuay-X2gZ"
      },
      "outputs": [],
      "source": [
        "tru_llm_standalone = TruCustomApp(\n",
        "    llm_standalone,\n",
        "    app_id=\"OpenAIChatCompletion\",\n",
        "    tags = \"comparison\",\n",
        "    feedbacks=[\n",
        "        f_qa_relevance,\n",
        "        f_groundtruth\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "idXs2pgHX2ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e73449-7746-4a48-ec5f-dbb258c2c844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Components:\n",
            "\tTruCustomApp (Custom) at 0x7d51083b16c0 with path __app__\n",
            "\tLLMStandaloneApp (Custom) at 0x7d510e336680 with path __app__.app\n",
            "\n",
            "Methods:\n",
            "Object at 0x7d510e336680:\n",
            "\t<function LLMStandaloneApp.__call__ at 0x7d510b2b1cf0> with path __app__.app\n"
          ]
        }
      ],
      "source": [
        "tru_llm_standalone.print_instrumented()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFFJEuM0X2ga"
      },
      "source": [
        "### Start using our apps!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2hRj2AiNX2ga"
      },
      "outputs": [],
      "source": [
        "prompt_set = [\n",
        "    \"What's the vibe like at oprhan andy's in SF?\",\n",
        "    \"What are the reviews like of Gola in SF?\",\n",
        "    \"Where's the best pizza in New York City\",\n",
        "    \"What's the address of Gumbo Social in San Francisco?\",\n",
        "    \"I'm in san francisco for the morning, does Juniper serve pastries?\",\n",
        "    \"What's the best diner in Toronto?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lX1RQ875X2ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6dea95-a78b-4260-ca22-ea1b299ad0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's the vibe like at oprhan andy's in SF?\n",
            "Added user message to memory: What's the vibe like at oprhan andy's in SF?\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"San Francisco\",\"term\":\"Orphan Andy's\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"What is the vibe like at Orphan Andy's in San Francisco?\"}\n",
            "Got output: The vibe at Orphan Andy's in San Francisco can be described as a classic American diner experience with a focus on breakfast and brunch offerings.\n",
            "========================\n",
            "\n",
            "What are the reviews like of Gola in SF?\n",
            "Added user message to memory: What are the reviews like of Gola in SF?\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"San Francisco\",\"term\":\"Gola\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"reviews of Gola in San Francisco\"}\n",
            "Got output: Gola in San Francisco has 113 reviews.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: business_reviews with args: {\"id\":\"6J4Y9CfQ7j7tj6q8b8KJ6g\"}\n",
            "Got output: Error: 404 Client Error: Not Found for url: https://api.yelp.com/v3/businesses/6J4Y9CfQ7j7tj6q8b8KJ6g/reviews\n",
            "========================\n",
            "\n",
            "Where's the best pizza in New York City\n",
            "Added user message to memory: Where's the best pizza in New York City\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"New York City\",\"term\":\"pizza\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"best pizza in New York City\"}\n",
            "Got output: L'industrie Pizzeria in Brooklyn has a rating of 4.7, making it one of the best pizza places in New York City according to the provided context information.\n",
            "========================\n",
            "\n",
            "What's the address of Gumbo Social in San Francisco?\n",
            "Added user message to memory: What's the address of Gumbo Social in San Francisco?\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"San Francisco\",\"term\":\"Gumbo Social\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"address of Gumbo Social in San Francisco\"}\n",
            "Got output: 5176 3rd St, San Francisco, CA 94124\n",
            "========================\n",
            "\n",
            "I'm in san francisco for the morning, does Juniper serve pastries?\n",
            "Added user message to memory: I'm in san francisco for the morning, does Juniper serve pastries?\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"san francisco\",\"term\":\"Juniper\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"Does Juniper serve pastries?\"}\n",
            "Got output: Yes.\n",
            "========================\n",
            "\n",
            "What's the best diner in Toronto?\n",
            "Added user message to memory: What's the best diner in Toronto?\n",
            "=== Calling Function ===\n",
            "Calling function: business_search with args: {\"location\":\"Toronto\",\"term\":\"diner\"}\n",
            "Got output: Content loaded! You can now search the information using read_business_search\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: read_business_search with args: {\"query\":\"What is the best diner in Toronto?\"}\n",
            "Got output: White Lily Diner\n",
            "========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for prompt in prompt_set:\n",
        "    print(prompt)\n",
        "\n",
        "    with tru_llm_standalone as recording:\n",
        "        llm_standalone(prompt)\n",
        "    record_standalone = recording.get()\n",
        "\n",
        "    with tru_agent as recording:\n",
        "         agent.query(prompt)\n",
        "    record_agent = recording.get()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XjJbak21iSF5"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}